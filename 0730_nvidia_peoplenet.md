```python
# ì™„ì „í•œ ë””ë²„ê¹… NVIDIA PeopleNet ì½”ë“œ (ê²½ë¡œ ìˆ˜ì • ë²„ì „)

import cv2
import numpy as np
import subprocess
import os
import json
import time
import onnxruntime as ort

class DebugNVIDIAPeopleNet:
    def __init__(self):
        """
        ë””ë²„ê¹… NVIDIA PeopleNet
        """
        print("ğŸš€ ë””ë²„ê¹… NVIDIA PeopleNet ì‹œì‘...")

        # ëª¨ë¸ ê²½ë¡œ ì„¤ì • (ìˆ˜ì •ë¨: ì‹¤ì œ ë‹¤ìš´ë¡œë“œëœ ê²½ë¡œ)
        self.model_path = "/workspace/peoplenet_vpruned_quantized_decrypted_v2.3.4/resnet34_peoplenet_int8.onnx"
        self.classes = ['person', 'bag', 'face']
        self.colors = [(0, 255, 0), (255, 0, 0), (0, 0, 255)]  # ë…¹ìƒ‰, íŒŒë‘, ë¹¨ê°•
        
        # model_loaded ì´ˆê¸°í™”
        self.model_loaded = False

        # ëª¨ë¸ ë¡œë“œ
        self.setup_model()

    def setup_model(self):
        """
        ëª¨ë¸ ì„¤ì •
        """
        try:
            print(f"ğŸ“ ëª¨ë¸ ê²½ë¡œ í™•ì¸: {self.model_path}")

            # íŒŒì¼ ì¡´ì¬ í™•ì¸
            if not os.path.exists(self.model_path):
                print("âŒ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ëª¨ë¸ì„ ì°¾ëŠ” ì¤‘...")
                self.find_model()
                return

            # ONNX Runtime ì„¤ì •
            providers = ['CPUExecutionProvider']
            self.session = ort.InferenceSession(self.model_path, providers=providers)

            # ì…ì¶œë ¥ ì •ë³´
            input_info = self.session.get_inputs()[0]
            output_info = self.session.get_outputs()

            self.input_name = input_info.name
            self.output_names = [output.name for output in output_info]

            print(f"âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
            print(f"ğŸ“Š ì…ë ¥: {input_info.name}, í˜•íƒœ: {input_info.shape}")
            print(f"ğŸ“Š ì¶œë ¥ ê°œìˆ˜: {len(output_info)}")

            self.model_loaded = True

            # í…ŒìŠ¤íŠ¸ ì¶”ë¡ 
            self.test_model()

        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.model_loaded = False

    def find_model(self):
        """
        ëª¨ë¸ íŒŒì¼ ì°¾ê¸°
        """
        import glob

        search_patterns = [
            "/workspace/peoplenet*/resnet34_peoplenet_int8.onnx",
            "/workspace/*/resnet34_peoplenet_int8.onnx",
            "/workspace/peoplenet*/*.onnx"
        ]

        print("ğŸ” ëª¨ë¸ ê²€ìƒ‰ ì¤‘...")
        for pattern in search_patterns:
            print(f"   ê²€ìƒ‰: {pattern}")
            files = glob.glob(pattern)
            if files:
                self.model_path = files[0]
                print(f"âœ… ëª¨ë¸ ë°œê²¬: {self.model_path}")
                self.setup_model()
                return

        print("âŒ NVIDIA PeopleNet ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        print("ğŸ’¡ NGCì—ì„œ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”:")
        print("   !./ngc-cli/ngc registry model download-version nvidia/tao/peoplenet:pruned_quantized_decrypted_v2.3.4")
        self.model_loaded = False

    def test_model(self):
        """
        ëª¨ë¸ í…ŒìŠ¤íŠ¸
        """
        try:
            print("ğŸ§ª ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì¤‘...")

            # ë”ë¯¸ ì…ë ¥
            dummy_input = np.random.randn(1, 3, 544, 960).astype(np.float32)
            outputs = self.session.run(self.output_names, {self.input_name: dummy_input})

            print(f"âœ… í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
            for i, output in enumerate(outputs):
                print(f"   ì¶œë ¥ {i}: {output.shape}, ë²”ìœ„ [{output.min():.3f}, {output.max():.3f}]")

        except Exception as e:
            print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

    def preprocess_frame(self, frame):
        """
        í”„ë ˆì„ ì „ì²˜ë¦¬
        """
        # 960x544ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
        resized = cv2.resize(frame, (960, 544))

        # BGR â†’ RGB
        rgb_frame = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)

        # ì •ê·œí™”
        normalized = rgb_frame.astype(np.float32) / 255.0

        # HWC â†’ CHW
        chw_frame = np.transpose(normalized, (2, 0, 1))

        # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
        batch_frame = np.expand_dims(chw_frame, axis=0)

        return batch_frame

    def detect_people(self, frame, debug=True):
        """
        ì‚¬ëŒ ê²€ì¶œ (ë””ë²„ê¹… ëª¨ë“œ)
        """
        if not self.model_loaded:
            if debug:
                print("âŒ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•ŠìŒ")
            return []

        try:
            if debug:
                print(f"ğŸ” ì…ë ¥ í”„ë ˆì„: {frame.shape}")

            # ì „ì²˜ë¦¬
            input_data = self.preprocess_frame(frame)
            if debug:
                print(f"ğŸ“Š ì „ì²˜ë¦¬ ì™„ë£Œ: {input_data.shape}")

            # ì¶”ë¡ 
            outputs = self.session.run(self.output_names, {self.input_name: input_data})
            if debug:
                print(f"ğŸ¤– ì¶”ë¡  ì™„ë£Œ")
                for i, output in enumerate(outputs):
                    print(f"   ì¶œë ¥ {i}: {output.shape}")
                    print(f"   ë²”ìœ„: [{output.min():.4f}, {output.max():.4f}]")
                    print(f"   í‰ê· : {output.mean():.4f}")

                    # ë†’ì€ ê°’ ê°œìˆ˜ í™•ì¸ (ìˆ˜ì •ë¨: np.sum ì‚¬ìš©)
                    high_01 = np.sum(output > 0.1)
                    high_03 = np.sum(output > 0.3)
                    high_05 = np.sum(output > 0.5)
                    print(f"   ê°’ ë¶„í¬: >0.1({high_01}), >0.3({high_03}), >0.5({high_05})")

            # í›„ì²˜ë¦¬
            detections = self.postprocess_debug(outputs, frame.shape, debug=debug)

            if debug:
                print(f"ğŸ¯ ìµœì¢… ê²€ì¶œ: {len(detections)}ê°œ")
                for det in detections:
                    print(f"   - {det['class']}: {det['confidence']:.3f}")

            return detections

        except Exception as e:
            if debug:
                print(f"âŒ ê²€ì¶œ ì˜¤ë¥˜: {e}")
                import traceback
                traceback.print_exc()
            return []

    def postprocess_debug(self, outputs, original_shape, debug=True):
        """
        ë””ë²„ê¹… í›„ì²˜ë¦¬
        """
        detections = []

        try:
            predictions = outputs[0]  # ì²« ë²ˆì§¸ ì¶œë ¥
            orig_h, orig_w = original_shape[:2]

            if debug:
                print(f"ğŸ” í›„ì²˜ë¦¬ ì‹œì‘: {predictions.shape}")

            # ë°°ì¹˜ ì°¨ì› ì œê±°
            if len(predictions.shape) == 4:
                predictions = predictions[0]  # (3, 34, 60)

            num_classes, grid_h, grid_w = predictions.shape

            if debug:
                print(f"ğŸ“Š ê·¸ë¦¬ë“œ: {num_classes} í´ë˜ìŠ¤, {grid_h}x{grid_w}")

            # ê° í´ë˜ìŠ¤ë³„ ì²˜ë¦¬
            for class_idx in range(min(num_classes, len(self.classes))):
                class_name = self.classes[class_idx]
                class_pred = predictions[class_idx]  # (34, 60)

                # ìµœê³ ê°’ ì°¾ê¸°
                max_val = float(class_pred.max())
                if debug:
                    print(f"   {class_name} ìµœëŒ€ê°’: {max_val:.4f}")

                # ë‹¤ì–‘í•œ ì„ê³„ê°’ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
                thresholds = [0.1, 0.2, 0.3, 0.4, 0.5]

                for threshold in thresholds:
                    high_positions = np.where(class_pred > threshold)

                    if len(high_positions[0]) > 0:
                        if debug:
                            print(f"   {class_name} ì„ê³„ê°’ {threshold}: {len(high_positions[0])}ê°œ í›„ë³´")

                        # ìƒìœ„ 5ê°œë§Œ ì²˜ë¦¬
                        for i in range(min(5, len(high_positions[0]))):
                            y_idx = high_positions[0][i]
                            x_idx = high_positions[1][i]
                            confidence = float(class_pred[y_idx, x_idx])

                            # ì¢Œí‘œ ë³€í™˜
                            center_x = (x_idx + 0.5) / grid_w
                            center_y = (y_idx + 0.5) / grid_h

                            # ë°”ìš´ë”© ë°•ìŠ¤ í¬ê¸°
                            if class_name == 'person':
                                box_w, box_h = 0.12, 0.20
                            elif class_name == 'bag':
                                box_w, box_h = 0.06, 0.08
                            else:  # face
                                box_w, box_h = 0.04, 0.05

                            # ì´ë¯¸ì§€ ì¢Œí‘œë¡œ ë³€í™˜
                            x1 = int((center_x - box_w/2) * orig_w)
                            y1 = int((center_y - box_h/2) * orig_h)
                            x2 = int((center_x + box_w/2) * orig_w)
                            y2 = int((center_y + box_h/2) * orig_h)

                            # ê²½ê³„ ì²´í¬
                            x1 = max(0, min(x1, orig_w-1))
                            y1 = max(0, min(y1, orig_h-1))
                            x2 = max(x1+10, min(x2, orig_w))
                            y2 = max(y1+10, min(y2, orig_h))

                            detections.append({
                                'bbox': [x1, y1, x2, y2],
                                'confidence': confidence,
                                'class_id': class_idx,
                                'class': class_name,
                                'method': f'Debug_T{threshold}'
                            })

                        break  # ì²« ë²ˆì§¸ ì„±ê³µí•˜ëŠ” ì„ê³„ê°’ì—ì„œ ì¤‘ë‹¨

            # ì¤‘ë³µ ì œê±° (ê°„ë‹¨ë²„ì „)
            if detections:
                detections = self.simple_nms(detections)

        except Exception as e:
            if debug:
                print(f"âŒ í›„ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                import traceback
                traceback.print_exc()

        return detections

    def simple_nms(self, detections, iou_threshold=0.5):
        """
        ê°„ë‹¨í•œ NMS
        """
        if not detections:
            return detections

        # ì‹ ë¢°ë„ ìˆœ ì •ë ¬
        detections = sorted(detections, key=lambda x: x['confidence'], reverse=True)

        final_detections = []

        for current in detections:
            should_keep = True

            for kept in final_detections:
                if current['class'] == kept['class']:
                    iou = self.calculate_iou(current['bbox'], kept['bbox'])
                    if iou > iou_threshold:
                        should_keep = False
                        break

            if should_keep:
                final_detections.append(current)

        return final_detections

    def calculate_iou(self, box1, box2):
        """
        IoU ê³„ì‚°
        """
        x1_1, y1_1, x2_1, y2_1 = box1
        x1_2, y1_2, x2_2, y2_2 = box2

        # êµì§‘í•©
        x1_i = max(x1_1, x1_2)
        y1_i = max(y1_1, y1_2)
        x2_i = min(x2_1, x2_2)
        y2_i = min(y2_1, y2_2)

        if x2_i <= x1_i or y2_i <= y1_i:
            return 0.0

        intersection = (x2_i - x1_i) * (y2_i - y1_i)

        # í•©ì§‘í•©
        area1 = (x2_1 - x1_1) * (y2_1 - y1_1)
        area2 = (x2_2 - x1_2) * (y2_2 - y1_2)
        union = area1 + area2 - intersection

        return intersection / union if union > 0 else 0.0

    def draw_detections(self, frame, detections):
        """
        ê²€ì¶œ ê²°ê³¼ ê·¸ë¦¬ê¸°
        """
        result_frame = frame.copy()  # ì›ë³¸ ë³´ì¡´
        
        for detection in detections:
            x1, y1, x2, y2 = detection['bbox']
            confidence = detection['confidence']
            class_name = detection['class']
            class_id = detection['class_id']
            method = detection.get('method', 'Unknown')

            # ìƒ‰ìƒ
            color = self.colors[class_id]

            # ë°”ìš´ë”© ë°•ìŠ¤
            cv2.rectangle(result_frame, (x1, y1), (x2, y2), color, 2)

            # ë¼ë²¨
            label = f"{class_name}: {confidence:.2f} ({method})"
            cv2.putText(result_frame, label, (x1, y1-10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)

        return result_frame

    def download_youtube_video(self, url):
        """
        YouTube ë‹¤ìš´ë¡œë“œ
        """
        try:
            print(f"ğŸ“º YouTube ë‹¤ìš´ë¡œë“œ: {url}")
            output_path = "/workspace/debug_input_video.mp4"
            
            # ì´ë¯¸ ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
            if os.path.exists(output_path):
                print(f"âœ… ê¸°ì¡´ ë¹„ë””ì˜¤ íŒŒì¼ ì‚¬ìš©: {output_path}")
                return output_path

            cmd = ["yt-dlp", "--format", "best[height<=720]", "--output", output_path, url]
            print("â³ ë‹¤ìš´ë¡œë“œ ì¤‘... (ì‹œê°„ì´ ì¢€ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)

            if os.path.exists(output_path):
                print(f"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {output_path}")
                return output_path
            return None

        except Exception as e:
            print(f"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None

    def test_video_frames(self, video_path, num_frames=5):
        """
        ë¹„ë””ì˜¤ í”„ë ˆì„ í…ŒìŠ¤íŠ¸
        """
        if not os.path.exists(video_path):
            print(f"âŒ ë¹„ë””ì˜¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {video_path}")
            return

        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            print("âŒ ë¹„ë””ì˜¤ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return

        # ë¹„ë””ì˜¤ ì •ë³´ ì¶œë ¥
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        print(f"ğŸ“Š ë¹„ë””ì˜¤ ì •ë³´: ì´ {total_frames} í”„ë ˆì„, {fps} FPS")
        print(f"ğŸ¬ {num_frames}ê°œ í”„ë ˆì„ í…ŒìŠ¤íŠ¸ ì‹œì‘...")

        frame_interval = max(1, total_frames // num_frames)  # 0 ë°©ì§€

        for i in range(num_frames):
            # í”„ë ˆì„ ìœ„ì¹˜ ê³„ì‚°
            frame_pos = min(i * frame_interval, total_frames - 1)
            
            # í”„ë ˆì„ ì´ë™
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_pos)

            ret, frame = cap.read()
            if not ret:
                print(f"âš ï¸  í”„ë ˆì„ {frame_pos} ì½ê¸° ì‹¤íŒ¨, ê±´ë„ˆëœ€")
                continue

            print(f"\nğŸ¯ í”„ë ˆì„ {frame_pos}/{total_frames} í…ŒìŠ¤íŠ¸:")
            detections = self.detect_people(frame, debug=True)

            if detections:
                print(f"âœ… {len(detections)}ê°œ ê²€ì¶œ ì„±ê³µ!")
                for det in detections:
                    print(f"   - {det['class']}: {det['confidence']:.3f}")
                
                # ê²€ì¶œ ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥
                result_frame = self.draw_detections(frame, detections)
                output_path = f"/workspace/frame_{frame_pos}_detection.jpg"
                cv2.imwrite(output_path, result_frame)
                print(f"   ğŸ’¾ ê²°ê³¼ ì €ì¥: {output_path}")
            else:
                print("âŒ ê²€ì¶œ ì—†ìŒ")

        cap.release()
        print("\nğŸ í”„ë ˆì„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")

# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
def run_debug_peoplenet():
    """
    ë””ë²„ê¹… PeopleNet ì‹¤í–‰
    """
    print("ğŸ”§ ë””ë²„ê¹… NVIDIA PeopleNet ì‹œì‘")
    print("=" * 60)

    # ë¶„ì„ê¸° ìƒì„±
    analyzer = DebugNVIDIAPeopleNet()

    if not analyzer.model_loaded:
        print("âŒ ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ğŸ’¡ ëª¨ë¸ì´ ë‹¤ìš´ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”:")
        print("   !ls -la /workspace/peoplenet*")
        return None

    # YouTube ë™ì˜ìƒ ë‹¤ìš´ë¡œë“œ
    youtube_url = "https://www.youtube.com/watch?v=SzRzYvQq0aQ"
    video_path = analyzer.download_youtube_video(youtube_url)

    if not video_path:
        print("âŒ ë™ì˜ìƒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
        return None

    # í”„ë ˆì„ í…ŒìŠ¤íŠ¸
    analyzer.test_video_frames(video_path, num_frames=5)

    return analyzer

# ì‹¤í–‰
if __name__ == "__main__":
    print("ğŸš€ ì™„ì „í•œ ë””ë²„ê¹… PeopleNet ì½”ë“œ (ê²½ë¡œ ìˆ˜ì • ë²„ì „)")
    print("ğŸ” ìƒì„¸í•œ ë¡œê·¸ì™€ í•¨ê»˜ ì‹¤í–‰ë©ë‹ˆë‹¤")
    print("=" * 60)
    result = run_debug_peoplenet()
    
    if result:
        print("\nâœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print("ğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
        print("   - ê²€ì¶œ ê²°ê³¼ í™•ì¸: /workspace/frame_*_detection.jpg")
        print("   - ë¹„ë””ì˜¤ ì „ì²´ ì²˜ë¦¬: analyzer.test_video_frames(video_path, num_frames=30)")
```

    ğŸš€ ì™„ì „í•œ ë””ë²„ê¹… PeopleNet ì½”ë“œ (ê²½ë¡œ ìˆ˜ì • ë²„ì „)
    ğŸ” ìƒì„¸í•œ ë¡œê·¸ì™€ í•¨ê»˜ ì‹¤í–‰ë©ë‹ˆë‹¤
    ============================================================
    ğŸ”§ ë””ë²„ê¹… NVIDIA PeopleNet ì‹œì‘
    ============================================================
    ğŸš€ ë””ë²„ê¹… NVIDIA PeopleNet ì‹œì‘...
    ğŸ“ ëª¨ë¸ ê²½ë¡œ í™•ì¸: /workspace/peoplenet_vpruned_quantized_decrypted_v2.3.4/resnet34_peoplenet_int8.onnx
    âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ!
    ğŸ“Š ì…ë ¥: input_1:0, í˜•íƒœ: ['unk__344', 3, 544, 960]
    ğŸ“Š ì¶œë ¥ ê°œìˆ˜: 2
    ğŸ§ª ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì¤‘...
    âœ… í…ŒìŠ¤íŠ¸ ì„±ê³µ!
       ì¶œë ¥ 0: (1, 3, 34, 60), ë²”ìœ„ [0.000, 0.097]
       ì¶œë ¥ 1: (1, 12, 34, 60), ë²”ìœ„ [-1.887, 10.847]
    ğŸ“º YouTube ë‹¤ìš´ë¡œë“œ: https://www.youtube.com/watch?v=SzRzYvQq0aQ
    â³ ë‹¤ìš´ë¡œë“œ ì¤‘... (ì‹œê°„ì´ ì¢€ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)
    âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: /workspace/debug_input_video.mp4
    ğŸ“Š ë¹„ë””ì˜¤ ì •ë³´: ì´ 2795 í”„ë ˆì„, 29 FPS
    ğŸ¬ 5ê°œ í”„ë ˆì„ í…ŒìŠ¤íŠ¸ ì‹œì‘...
    
    ğŸ¯ í”„ë ˆì„ 0/2795 í…ŒìŠ¤íŠ¸:
    ğŸ” ì…ë ¥ í”„ë ˆì„: (360, 640, 3)
    ğŸ“Š ì „ì²˜ë¦¬ ì™„ë£Œ: (1, 3, 544, 960)
    ğŸ¤– ì¶”ë¡  ì™„ë£Œ
       ì¶œë ¥ 0: (1, 3, 34, 60)
       ë²”ìœ„: [0.0000, 0.4319]
       í‰ê· : 0.0019
       ê°’ ë¶„í¬: >0.1(18), >0.3(11), >0.5(0)
       ì¶œë ¥ 1: (1, 12, 34, 60)
       ë²”ìœ„: [-3.5740, 10.4456]
       í‰ê· : 0.8679
       ê°’ ë¶„í¬: >0.1(14916), >0.3(13460), >0.5(11734)
    ğŸ” í›„ì²˜ë¦¬ ì‹œì‘: (1, 3, 34, 60)
    ğŸ“Š ê·¸ë¦¬ë“œ: 3 í´ë˜ìŠ¤, 34x60
       person ìµœëŒ€ê°’: 0.0913
       bag ìµœëŒ€ê°’: 0.0000
       face ìµœëŒ€ê°’: 0.4319
       face ì„ê³„ê°’ 0.1: 18ê°œ í›„ë³´
    ğŸ¯ ìµœì¢… ê²€ì¶œ: 5ê°œ
       - face: 0.421
       - face: 0.395
       - face: 0.214
       - face: 0.204
       - face: 0.190
    âœ… 5ê°œ ê²€ì¶œ ì„±ê³µ!
       - face: 0.421
       - face: 0.395
       - face: 0.214
       - face: 0.204
       - face: 0.190
       ğŸ’¾ ê²°ê³¼ ì €ì¥: /workspace/frame_0_detection.jpg
    
    ğŸ¯ í”„ë ˆì„ 559/2795 í…ŒìŠ¤íŠ¸:
    ğŸ” ì…ë ¥ í”„ë ˆì„: (360, 640, 3)
    ğŸ“Š ì „ì²˜ë¦¬ ì™„ë£Œ: (1, 3, 544, 960)
    ğŸ¤– ì¶”ë¡  ì™„ë£Œ
       ì¶œë ¥ 0: (1, 3, 34, 60)
       ë²”ìœ„: [0.0000, 0.1677]
       í‰ê· : 0.0015
       ê°’ ë¶„í¬: >0.1(5), >0.3(0), >0.5(0)
       ì¶œë ¥ 1: (1, 12, 34, 60)
       ë²”ìœ„: [-3.1551, 10.9345]
       í‰ê· : 1.3959
       ê°’ ë¶„í¬: >0.1(15228), >0.3(14321), >0.5(12971)
    ğŸ” í›„ì²˜ë¦¬ ì‹œì‘: (1, 3, 34, 60)
    ğŸ“Š ê·¸ë¦¬ë“œ: 3 í´ë˜ìŠ¤, 34x60
       person ìµœëŒ€ê°’: 0.1677
       person ì„ê³„ê°’ 0.1: 5ê°œ í›„ë³´
       bag ìµœëŒ€ê°’: 0.0000
       face ìµœëŒ€ê°’: 0.0212
    ğŸ¯ ìµœì¢… ê²€ì¶œ: 3ê°œ
       - person: 0.168
       - person: 0.137
       - person: 0.100
    âœ… 3ê°œ ê²€ì¶œ ì„±ê³µ!
       - person: 0.168
       - person: 0.137
       - person: 0.100
       ğŸ’¾ ê²°ê³¼ ì €ì¥: /workspace/frame_559_detection.jpg
    
    ğŸ¯ í”„ë ˆì„ 1118/2795 í…ŒìŠ¤íŠ¸:
    ğŸ” ì…ë ¥ í”„ë ˆì„: (360, 640, 3)
    ğŸ“Š ì „ì²˜ë¦¬ ì™„ë£Œ: (1, 3, 544, 960)
    ğŸ¤– ì¶”ë¡  ì™„ë£Œ
       ì¶œë ¥ 0: (1, 3, 34, 60)
       ë²”ìœ„: [0.0000, 0.8186]
       í‰ê· : 0.0162
       ê°’ ë¶„í¬: >0.1(322), >0.3(98), >0.5(15)
       ì¶œë ¥ 1: (1, 12, 34, 60)
       ë²”ìœ„: [-4.8532, 10.7379]
       í‰ê· : 1.1863
       ê°’ ë¶„í¬: >0.1(14764), >0.3(13377), >0.5(11667)
    ğŸ” í›„ì²˜ë¦¬ ì‹œì‘: (1, 3, 34, 60)
    ğŸ“Š ê·¸ë¦¬ë“œ: 3 í´ë˜ìŠ¤, 34x60
       person ìµœëŒ€ê°’: 0.5633
       person ì„ê³„ê°’ 0.1: 231ê°œ í›„ë³´
       bag ìµœëŒ€ê°’: 0.0000
       face ìµœëŒ€ê°’: 0.8186
       face ì„ê³„ê°’ 0.1: 91ê°œ í›„ë³´
    ğŸ¯ ìµœì¢… ê²€ì¶œ: 7ê°œ
       - face: 0.388
       - face: 0.374
       - person: 0.281
       - face: 0.178
       - face: 0.156
       - person: 0.143
       - face: 0.106
    âœ… 7ê°œ ê²€ì¶œ ì„±ê³µ!
       - face: 0.388
       - face: 0.374
       - person: 0.281
       - face: 0.178
       - face: 0.156
       - person: 0.143
       - face: 0.106
       ğŸ’¾ ê²°ê³¼ ì €ì¥: /workspace/frame_1118_detection.jpg
    
    ğŸ¯ í”„ë ˆì„ 1677/2795 í…ŒìŠ¤íŠ¸:
    ğŸ” ì…ë ¥ í”„ë ˆì„: (360, 640, 3)
    ğŸ“Š ì „ì²˜ë¦¬ ì™„ë£Œ: (1, 3, 544, 960)
    ğŸ¤– ì¶”ë¡  ì™„ë£Œ
       ì¶œë ¥ 0: (1, 3, 34, 60)
       ë²”ìœ„: [0.0000, 0.9709]
       í‰ê· : 0.0177
       ê°’ ë¶„í¬: >0.1(328), >0.3(114), >0.5(30)
       ì¶œë ¥ 1: (1, 12, 34, 60)
       ë²”ìœ„: [-3.2638, 11.2693]
       í‰ê· : 1.1525
       ê°’ ë¶„í¬: >0.1(14739), >0.3(13327), >0.5(11610)
    ğŸ” í›„ì²˜ë¦¬ ì‹œì‘: (1, 3, 34, 60)
    ğŸ“Š ê·¸ë¦¬ë“œ: 3 í´ë˜ìŠ¤, 34x60
       person ìµœëŒ€ê°’: 0.5510
       person ì„ê³„ê°’ 0.1: 187ê°œ í›„ë³´
       bag ìµœëŒ€ê°’: 0.0000
       face ìµœëŒ€ê°’: 0.9709
       face ì„ê³„ê°’ 0.1: 141ê°œ í›„ë³´
    ğŸ¯ ìµœì¢… ê²€ì¶œ: 6ê°œ
       - face: 0.175
       - person: 0.161
       - face: 0.156
       - face: 0.119
       - face: 0.111
       - face: 0.108
    âœ… 6ê°œ ê²€ì¶œ ì„±ê³µ!
       - face: 0.175
       - person: 0.161
       - face: 0.156
       - face: 0.119
       - face: 0.111
       - face: 0.108
       ğŸ’¾ ê²°ê³¼ ì €ì¥: /workspace/frame_1677_detection.jpg
    
    ğŸ¯ í”„ë ˆì„ 2236/2795 í…ŒìŠ¤íŠ¸:
    ğŸ” ì…ë ¥ í”„ë ˆì„: (360, 640, 3)
    ğŸ“Š ì „ì²˜ë¦¬ ì™„ë£Œ: (1, 3, 544, 960)
    ğŸ¤– ì¶”ë¡  ì™„ë£Œ
       ì¶œë ¥ 0: (1, 3, 34, 60)
       ë²”ìœ„: [0.0000, 0.7440]
       í‰ê· : 0.0089
       ê°’ ë¶„í¬: >0.1(160), >0.3(57), >0.5(16)
       ì¶œë ¥ 1: (1, 12, 34, 60)
       ë²”ìœ„: [-2.7482, 10.8977]
       í‰ê· : 1.1427
       ê°’ ë¶„í¬: >0.1(14986), >0.3(13584), >0.5(11692)
    ğŸ” í›„ì²˜ë¦¬ ì‹œì‘: (1, 3, 34, 60)
    ğŸ“Š ê·¸ë¦¬ë“œ: 3 í´ë˜ìŠ¤, 34x60
       person ìµœëŒ€ê°’: 0.7440
       person ì„ê³„ê°’ 0.1: 160ê°œ í›„ë³´
       bag ìµœëŒ€ê°’: 0.0000
       face ìµœëŒ€ê°’: 0.0920
    ğŸ¯ ìµœì¢… ê²€ì¶œ: 3ê°œ
       - person: 0.268
       - person: 0.190
       - person: 0.144
    âœ… 3ê°œ ê²€ì¶œ ì„±ê³µ!
       - person: 0.268
       - person: 0.190
       - person: 0.144
       ğŸ’¾ ê²°ê³¼ ì €ì¥: /workspace/frame_2236_detection.jpg
    
    ğŸ í”„ë ˆì„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ
    
    âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!
    ğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:
       - ê²€ì¶œ ê²°ê³¼ í™•ì¸: /workspace/frame_*_detection.jpg
       - ë¹„ë””ì˜¤ ì „ì²´ ì²˜ë¦¬: analyzer.test_video_frames(video_path, num_frames=30)



```python

```
