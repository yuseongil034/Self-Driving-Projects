{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMVWEsqRpR2YCysFLLV9YDN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuseongil034/yuseongil/blob/main/0718_yolo11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLO v11 설치\n",
        "!pip install ultralytics\n",
        "\n",
        "from google.colab import files\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# COCO 사전 훈련된 YOLOv11n 모델 로드\n",
        "model = YOLO(\"yolo11n.pt\")\n",
        "\n",
        "# 모델 정보 표시 (선택사항)\n",
        "model.info()\n",
        "\n",
        "# COCO8 예제 데이터셋으로 10 에포크 훈련\n",
        "results = model.train(data=\"coco8.yaml\", epochs=10, imgsz=640)\n",
        "\n",
        "# 사진 업로드하고 경로 설정\n",
        "uploaded = files.upload()\n",
        "image_path = list(uploaded.keys())[0]\n",
        "\n",
        "# 업로드한 이미지에 대해 YOLOv11n 모델로 추론 실행\n",
        "results = model(image_path)\n",
        "results[0].show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1WUa2TYjABmj",
        "outputId": "10ab9078-fddc-41b5-d32e-e70ee25aeb32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.167)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.7.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "YOLO11n summary: 181 layers, 2,624,080 parameters, 0 gradients, 6.6 GFLOPs\n",
            "Ultralytics 8.3.167 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=coco8.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/train2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    464912  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
            "YOLO11n summary: 181 layers, 2,624,080 parameters, 2,624,064 gradients, 6.6 GFLOPs\n",
            "\n",
            "Transferred 499/499 items from pretrained weights\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1074.6±304.3 MB/s, size: 50.0 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/coco8/labels/train.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 346.9±80.2 MB/s, size: 54.0 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train2\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/10     0.693G      1.034      1.832      1.384         13        640: 100%|██████████| 1/1 [00:00<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  8.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         17      0.588       0.85      0.878      0.633\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/10     0.723G     0.9838      2.981      1.399         13        640: 100%|██████████| 1/1 [00:00<00:00,  7.66it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 12.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         17      0.582       0.85      0.849      0.631\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/10     0.723G      1.015      1.971      1.422         13        640: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 13.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         17      0.599       0.85      0.849      0.647\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/10     0.723G      1.088      2.282      1.467         13        640: 100%|██████████| 1/1 [00:00<00:00,  7.00it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 17.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         17       0.61       0.85       0.85      0.649\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/10     0.727G     0.9845      2.238      1.399         13        640: 100%|██████████| 1/1 [00:00<00:00,  8.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 16.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         17      0.622       0.85      0.852      0.633\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/10     0.729G      1.259      2.219      1.687         13        640: 100%|██████████| 1/1 [00:00<00:00,  7.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 17.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         17      0.626       0.85      0.854      0.635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/10     0.748G      1.147      2.419       1.27         13        640: 100%|██████████| 1/1 [00:00<00:00,  7.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 17.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         17      0.637       0.85       0.87      0.633\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/10     0.764G     0.9046      2.267      1.292         13        640: 100%|██████████| 1/1 [00:00<00:00,  6.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 18.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         17      0.644       0.85      0.856      0.632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/10     0.779G     0.9919      1.789      1.258         13        640: 100%|██████████| 1/1 [00:00<00:00,  7.32it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 18.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         17      0.648       0.85      0.856      0.624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/10     0.795G     0.9611      2.103      1.425         13        640: 100%|██████████| 1/1 [00:00<00:00,  6.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 17.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         17      0.641       0.85      0.861      0.626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "10 epochs completed in 0.002 hours.\n",
            "Optimizer stripped from runs/detect/train2/weights/last.pt, 5.5MB\n",
            "Optimizer stripped from runs/detect/train2/weights/best.pt, 5.5MB\n",
            "\n",
            "Validating runs/detect/train2/weights/best.pt...\n",
            "Ultralytics 8.3.167 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 24.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all          4         17      0.612       0.85       0.85      0.648\n",
            "                person          3         10      0.597        0.6      0.593      0.269\n",
            "                   dog          1          1      0.552          1      0.995      0.796\n",
            "                 horse          1          2        0.7          1      0.995      0.674\n",
            "              elephant          1          2      0.378        0.5      0.527      0.258\n",
            "              umbrella          1          1      0.582          1      0.995      0.995\n",
            "          potted plant          1          1      0.867          1      0.995      0.895\n",
            "Speed: 0.3ms preprocess, 4.1ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-298a3603-7a7c-4466-9860-1d92a66ff3c6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-298a3603-7a7c-4466-9860-1d92a66ff3c6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-23-1230931348.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# 사진 업로드하고 경로 설정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muploaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# 업로드한 이미지에 대해 YOLOv11n 모델로 추론 실행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Colab용 YouTube YOLO 영상 처리기\n",
        "# 이 코드를 하나의 셀에서 실행하세요\n",
        "\n",
        "# 1. 필요한 패키지 설치\n",
        "print(\"📦 패키지 설치 중...\")\n",
        "!pip install ultralytics yt-dlp opencv-python matplotlib -q\n",
        "\n",
        "# 2. 라이브러리 임포트\n",
        "import cv2\n",
        "import yt_dlp\n",
        "import tempfile\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import logging\n",
        "from pathlib import Path\n",
        "from typing import Optional, Tuple, List, Dict, Any\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# 로깅 설정\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Jupyter 환경 감지\n",
        "try:\n",
        "    from IPython.display import clear_output, display, HTML\n",
        "    JUPYTER_ENV = True\n",
        "except ImportError:\n",
        "    JUPYTER_ENV = False\n",
        "    def clear_output(wait=True):\n",
        "        pass\n",
        "\n",
        "class YOLOVideoProcessor:\n",
        "    \"\"\"\n",
        "    YouTube 영상 처리기 with YOLOv11 객체 탐지\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_path: str = \"yolo11n.pt\"):\n",
        "        \"\"\"\n",
        "        처리기 초기화\n",
        "\n",
        "        Args:\n",
        "            model_path: YOLO 모델 경로\n",
        "        \"\"\"\n",
        "        self.model_path = model_path\n",
        "        self.model = None\n",
        "        self.stats = {\n",
        "            'total_frames_processed': 0,\n",
        "            'total_detections': 0,\n",
        "            'processing_time': 0,\n",
        "            'detected_classes': set()\n",
        "        }\n",
        "\n",
        "    def load_model(self) -> bool:\n",
        "        \"\"\"YOLOv11 모델 로드\"\"\"\n",
        "        try:\n",
        "            from ultralytics import YOLO\n",
        "            print(f\"🤖 YOLOv11 모델 로드 중: {self.model_path}\")\n",
        "            self.model = YOLO(self.model_path)\n",
        "            print(f\"✅ 모델 로드 완료!\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"❌ 모델 로드 실패: {e}\")\n",
        "            return False\n",
        "\n",
        "    def get_video_info(self, youtube_url: str) -> Optional[Dict[str, Any]]:\n",
        "        \"\"\"YouTube 영상 정보 가져오기\"\"\"\n",
        "        ydl_opts = {\n",
        "            'quiet': True,\n",
        "            'no_warnings': True,\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "                info = ydl.extract_info(youtube_url, download=False)\n",
        "                return {\n",
        "                    'title': info.get('title', '알 수 없음'),\n",
        "                    'duration': info.get('duration', 0),\n",
        "                    'uploader': info.get('uploader', '알 수 없음'),\n",
        "                    'view_count': info.get('view_count', 0),\n",
        "                    'upload_date': info.get('upload_date', '알 수 없음'),\n",
        "                    'url': youtube_url\n",
        "                }\n",
        "        except Exception as e:\n",
        "            print(f\"❌ 영상 정보 가져오기 실패: {e}\")\n",
        "            return None\n",
        "\n",
        "    def format_time(self, seconds: float) -> str:\n",
        "        \"\"\"초를 MM:SS 형식으로 변환\"\"\"\n",
        "        minutes = int(seconds // 60)\n",
        "        seconds = int(seconds % 60)\n",
        "        return f\"{minutes:02d}:{seconds:02d}\"\n",
        "\n",
        "    def process_video(self, youtube_url: str, output_filename: str = \"yolo_output.mp4\",\n",
        "                     start_time: float = 0, duration: int = 10, skip_frames: int = 3) -> bool:\n",
        "        \"\"\"\n",
        "        YouTube 영상을 YOLO 탐지로 처리\n",
        "\n",
        "        Args:\n",
        "            youtube_url: YouTube 영상 URL\n",
        "            output_filename: 출력 파일명\n",
        "            start_time: 시작 시간(초)\n",
        "            duration: 처리할 길이(초)\n",
        "            skip_frames: 건너뛸 프레임 수\n",
        "\n",
        "        Returns:\n",
        "            성공시 True, 실패시 False\n",
        "        \"\"\"\n",
        "        if not self.model and not self.load_model():\n",
        "            return False\n",
        "\n",
        "        # 다운로드 설정\n",
        "        ydl_opts = {\n",
        "            'format': 'mp4/best[height<=720]',\n",
        "            'outtmpl': '/tmp/temp_video.%(ext)s',\n",
        "            'quiet': True,\n",
        "        }\n",
        "\n",
        "        temp_video_path = None\n",
        "        cap = None\n",
        "        out = None\n",
        "\n",
        "        try:\n",
        "            # 영상 다운로드\n",
        "            print(\"⬇️ YouTube 영상 다운로드 중...\")\n",
        "            with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "                info = ydl.extract_info(youtube_url, download=True)\n",
        "                temp_video_path = ydl.prepare_filename(info)\n",
        "                print(f\"🎥 제목: {info['title']}\")\n",
        "                print(f\"📊 길이: {info.get('duration', '알 수 없음')}초\")\n",
        "\n",
        "            # 비디오 캡처 초기화\n",
        "            cap = cv2.VideoCapture(temp_video_path)\n",
        "            if not cap.isOpened():\n",
        "                raise ValueError(\"영상 파일을 열 수 없습니다\")\n",
        "\n",
        "            # 영상 속성 가져오기\n",
        "            fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "            frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "            frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "            video_duration = total_frames / fps\n",
        "\n",
        "            # 시간 범위 설정\n",
        "            end_time = min(start_time + duration, video_duration)\n",
        "            start_frame = int(start_time * fps)\n",
        "            end_frame = int(end_time * fps)\n",
        "\n",
        "            print(f\"📹 영상 정보: {frame_width}x{frame_height}, {fps:.2f} FPS\")\n",
        "            print(f\"🎯 처리 구간: {self.format_time(start_time)} ~ {self.format_time(end_time)}\")\n",
        "\n",
        "            # 시작 프레임으로 이동\n",
        "            if start_frame > 0:\n",
        "                cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
        "\n",
        "            # 비디오 라이터 초기화\n",
        "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "            output_fps = fps / skip_frames\n",
        "            out = cv2.VideoWriter(output_filename, fourcc, output_fps, (frame_width, frame_height))\n",
        "\n",
        "            # 프레임 처리\n",
        "            frame_num = start_frame\n",
        "            processed_frames = 0\n",
        "            start_processing_time = time.time()\n",
        "\n",
        "            print(\"🔄 YOLO 추론 시작...\")\n",
        "\n",
        "            while True:\n",
        "                ret, frame = cap.read()\n",
        "                if not ret or frame_num >= end_frame:\n",
        "                    break\n",
        "\n",
        "                # 프레임 건너뛰기\n",
        "                if (frame_num - start_frame) % skip_frames == 0:\n",
        "                    try:\n",
        "                        # YOLO 추론\n",
        "                        results = self.model.predict(\n",
        "                            frame,\n",
        "                            imgsz=640,\n",
        "                            verbose=False,\n",
        "                            show=False,\n",
        "                            save=False\n",
        "                        )[0]\n",
        "\n",
        "                        # 결과 시각화\n",
        "                        annotated_frame = results.plot()\n",
        "                        out.write(annotated_frame)\n",
        "                        processed_frames += 1\n",
        "\n",
        "                        # 통계 업데이트\n",
        "                        if results.boxes is not None:\n",
        "                            detections = len(results.boxes)\n",
        "                            self.stats['total_detections'] += detections\n",
        "\n",
        "                            # 탐지된 클래스 추적\n",
        "                            for box in results.boxes:\n",
        "                                class_id = int(box.cls[0])\n",
        "                                class_name = self.model.names[class_id]\n",
        "                                self.stats['detected_classes'].add(class_name)\n",
        "\n",
        "                        # 진행률 표시\n",
        "                        if processed_frames % 20 == 0:\n",
        "                            progress = ((frame_num - start_frame) / (end_frame - start_frame)) * 100\n",
        "                            print(f\"⏳ 진행률: {progress:.1f}% | 처리 프레임: {processed_frames}\")\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"⚠️ 프레임 {frame_num} 처리 중 오류: {e}\")\n",
        "                        continue\n",
        "\n",
        "                frame_num += 1\n",
        "\n",
        "            # 최종 통계\n",
        "            total_time = time.time() - start_processing_time\n",
        "            self.stats['processing_time'] = total_time\n",
        "            self.stats['total_frames_processed'] = processed_frames\n",
        "\n",
        "            print(f\"\\n✅ YOLO 영상 추론 완료!\")\n",
        "            print(f\"📊 처리 시간: {total_time:.2f}초\")\n",
        "            print(f\"📊 처리된 프레임: {processed_frames}\")\n",
        "            print(f\"📊 총 탐지 수: {self.stats['total_detections']}\")\n",
        "            print(f\"📊 탐지된 클래스: {', '.join(sorted(self.stats['detected_classes']))}\")\n",
        "            print(f\"💾 출력 파일: {output_filename}\")\n",
        "\n",
        "            # 파일 크기 확인\n",
        "            if os.path.exists(output_filename):\n",
        "                file_size = os.path.getsize(output_filename) / (1024*1024)\n",
        "                print(f\"📁 파일 크기: {file_size:.2f} MB\")\n",
        "\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ 오류 발생: {e}\")\n",
        "            return False\n",
        "\n",
        "        finally:\n",
        "            # 리소스 정리\n",
        "            if cap:\n",
        "                cap.release()\n",
        "            if out:\n",
        "                out.release()\n",
        "            if temp_video_path and os.path.exists(temp_video_path):\n",
        "                try:\n",
        "                    os.remove(temp_video_path)\n",
        "                    print(\"🗑️ 임시 파일 정리 완료\")\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "# 빠른 실행을 위한 함수\n",
        "def quick_process(youtube_url: str, start_time: float = 0, duration: int = 10):\n",
        "    \"\"\"빠른 처리를 위한 간단한 함수\"\"\"\n",
        "    print(\"🚀 빠른 YOLO 영상 처리 시작!\")\n",
        "    processor = YOLOVideoProcessor(\"yolo11n.pt\")\n",
        "    return processor.process_video(\n",
        "        youtube_url=youtube_url,\n",
        "        start_time=start_time,\n",
        "        duration=duration,\n",
        "        skip_frames=3\n",
        "    )\n",
        "\n",
        "# 사용 예시\n",
        "def example_usage():\n",
        "    \"\"\"사용 예시\"\"\"\n",
        "    print(\"💡 사용 예시:\")\n",
        "    print(\"quick_process('https://youtube.com/watch?v=...', start_time=30, duration=10)\")\n",
        "    print(\"\\n또는:\")\n",
        "    print(\"processor = YOLOVideoProcessor('yolo11n.pt')\")\n",
        "    print(\"processor.process_video('https://youtube.com/watch?v=...', start_time=0, duration=15)\")\n",
        "\n",
        "# 즉시 실행\n",
        "print(\"🎉 YOLO 영상 처리기 준비 완료!\")\n",
        "print(\"=\" * 50)\n",
        "example_usage()\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Google Colab에서 다운로드 기능 추가\n",
        "def download_result(filename: str = \"yolo_output.mp4\"):\n",
        "    \"\"\"결과 파일 다운로드\"\"\"\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        if os.path.exists(filename):\n",
        "            files.download(filename)\n",
        "            print(f\"📥 {filename} 다운로드 시작!\")\n",
        "        else:\n",
        "            print(f\"❌ {filename} 파일을 찾을 수 없습니다.\")\n",
        "    except ImportError:\n",
        "        print(\"❌ Google Colab 환경이 아닙니다.\")\n",
        "\n",
        "print(\"📥 결과 다운로드: download_result('yolo_output.mp4')\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZLWhH43B0e2",
        "outputId": "8b9d572a-09a8-4076-a14a-82b43a0ae83c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📦 패키지 설치 중...\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.3/174.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h🎉 YOLO 영상 처리기 준비 완료!\n",
            "==================================================\n",
            "💡 사용 예시:\n",
            "quick_process('https://youtube.com/watch?v=...', start_time=30, duration=10)\n",
            "\n",
            "또는:\n",
            "processor = YOLOVideoProcessor('yolo11n.pt')\n",
            "processor.process_video('https://youtube.com/watch?v=...', start_time=0, duration=15)\n",
            "==================================================\n",
            "📥 결과 다운로드: download_result('yolo_output.mp4')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kOfTf_p7XgI",
        "outputId": "f03b09b8-8c5a-4f1d-9734-c65efbc6d926"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🎥 YouTube YOLO 영상 처리기\n",
            "==================================================\n",
            "📋 YouTube 영상 URL을 입력하세요: https://youtu.be/JHva65QGlzE?si=7nbn3rIVcKcyDsVz\n",
            "\n",
            "🤖 사용 가능한 YOLOv11 모델:\n",
            "1. yolo11n.pt - YOLOv11 Nano - 가장 빠르고 가벼운 모델\n",
            "2. yolo11s.pt - YOLOv11 Small - 속도와 정확도의 균형\n",
            "3. yolo11m.pt - YOLOv11 Medium - 중간 크기 모델\n",
            "4. yolo11l.pt - YOLOv11 Large - 높은 정확도\n",
            "5. yolo11x.pt - YOLOv11 Extra Large - 최고 정확도\n",
            "\n",
            "모델을 선택하세요 (1-5, 기본값: 1): 5\n",
            "\n",
            "📹 제목: 서울의 홍대 홍익대 입구 근처의 최근 모습을 감상하세요 Travel destinations in Korea 韓国の目的地 4K\n",
            "⏱ 길이: 177초 (02:57)\n",
            "👤 업로더: Seoul_driver\n",
            "\n",
            "⏰ 처리할 구간을 선택하세요 (0~177초)\n",
            "🎬 시작 시간 (초 또는 분:초, 기본값: 0): 55\n",
            "🏁 종료 시간 (56.0초~177초, 기본값: 자동): 100\n",
            "💾 출력 파일명 (기본값: yolo_output.mp4): drive1\n",
            "⏭ 건너뛸 프레임 수 (기본값: 5): 3\n",
            "\n",
            "🎉 처리가 성공적으로 완료되었습니다!\n"
          ]
        }
      ],
      "source": [
        "# 먼저 필요한 패키지들을 설치하세요\n",
        "# !pip install ultralytics yt-dlp opencv-python matplotlib\n",
        "\n",
        "import cv2\n",
        "import yt_dlp\n",
        "import tempfile\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import logging\n",
        "from pathlib import Path\n",
        "from typing import Optional, Tuple, List, Dict, Any\n",
        "import argparse\n",
        "import json\n",
        "import sys\n",
        "from datetime import datetime\n",
        "\n",
        "# 로깅 설정\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Jupyter 환경 감지\n",
        "try:\n",
        "    from IPython.display import clear_output\n",
        "    JUPYTER_ENV = True\n",
        "except ImportError:\n",
        "    JUPYTER_ENV = False\n",
        "    def clear_output(wait=True):\n",
        "        pass\n",
        "\n",
        "# 전역 모델 변수\n",
        "model = None\n",
        "\n",
        "class YOLOVideoProcessor:\n",
        "    \"\"\"\n",
        "    향상된 YouTube 영상 처리기 with YOLOv11 객체 탐지\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_path: str = \"yolo11n.pt\"):\n",
        "        \"\"\"\n",
        "        처리기 초기화\n",
        "\n",
        "        Args:\n",
        "            model_path: YOLO 모델 경로\n",
        "        \"\"\"\n",
        "        self.model_path = model_path\n",
        "        self.model = None\n",
        "        self.stats = {\n",
        "            'total_frames_processed': 0,\n",
        "            'total_detections': 0,\n",
        "            'processing_time': 0,\n",
        "            'detected_classes': set()\n",
        "        }\n",
        "\n",
        "    def load_model(self) -> bool:\n",
        "        \"\"\"YOLOv11 모델 로드\"\"\"\n",
        "        try:\n",
        "            from ultralytics import YOLO\n",
        "            self.model = YOLO(self.model_path)\n",
        "            logger.info(f\"🤖 YOLOv11 모델 로드 완료: {self.model_path}\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            logger.error(f\"❌ YOLOv11 모델 로드 실패: {e}\")\n",
        "            logger.error(\"💡 ultralytics 설치 필요: pip install ultralytics>=8.0.0\")\n",
        "            return False\n",
        "\n",
        "    def get_video_info(self, youtube_url: str) -> Optional[Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        YouTube 영상 정보 가져오기\n",
        "\n",
        "        Args:\n",
        "            youtube_url: YouTube 영상 URL\n",
        "\n",
        "        Returns:\n",
        "            영상 정보 딕셔너리 또는 실패시 None\n",
        "        \"\"\"\n",
        "        ydl_opts = {\n",
        "            'quiet': True,\n",
        "            'no_warnings': True,\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "                info = ydl.extract_info(youtube_url, download=False)\n",
        "                return {\n",
        "                    'title': info.get('title', '알 수 없음'),\n",
        "                    'duration': info.get('duration', 0),\n",
        "                    'uploader': info.get('uploader', '알 수 없음'),\n",
        "                    'view_count': info.get('view_count', 0),\n",
        "                    'upload_date': info.get('upload_date', '알 수 없음'),\n",
        "                    'description': info.get('description', '')[:200] + '...' if info.get('description') else '',\n",
        "                    'url': youtube_url\n",
        "                }\n",
        "        except Exception as e:\n",
        "            logger.error(f\"❌ 영상 정보 가져오기 실패: {e}\")\n",
        "            return None\n",
        "\n",
        "    def validate_time_range(self, start_time: float, end_time: float, duration: float) -> Tuple[float, float]:\n",
        "        \"\"\"\n",
        "        시간 범위 검증 및 조정\n",
        "\n",
        "        Args:\n",
        "            start_time: 시작 시간(초)\n",
        "            end_time: 종료 시간(초)\n",
        "            duration: 영상 길이(초)\n",
        "\n",
        "        Returns:\n",
        "            검증된 (start_time, end_time) 튜플\n",
        "        \"\"\"\n",
        "        start_time = max(0, start_time)\n",
        "        end_time = min(end_time, duration)\n",
        "\n",
        "        if start_time >= end_time:\n",
        "            logger.warning(f\"잘못된 시간 범위: {start_time}-{end_time}, 마지막 10초 사용\")\n",
        "            end_time = duration\n",
        "            start_time = max(0, duration - 10)\n",
        "\n",
        "        return start_time, end_time\n",
        "\n",
        "    def format_time(self, seconds: float) -> str:\n",
        "        \"\"\"초를 MM:SS 형식으로 변환\"\"\"\n",
        "        minutes = int(seconds // 60)\n",
        "        seconds = int(seconds % 60)\n",
        "        return f\"{minutes:02d}:{seconds:02d}\"\n",
        "\n",
        "    def process_video(self, youtube_url: str, output_filename: str = \"yolo_output.mp4\",\n",
        "                     start_time: float = 0, end_time: Optional[float] = None,\n",
        "                     max_duration: int = 10, skip_frames: int = 5) -> bool:\n",
        "        \"\"\"\n",
        "        YouTube 영상을 YOLO 탐지로 처리\n",
        "\n",
        "        Args:\n",
        "            youtube_url: YouTube 영상 URL\n",
        "            output_filename: 출력 파일명\n",
        "            start_time: 시작 시간(초)\n",
        "            end_time: 종료 시간(초) (None이면 자동)\n",
        "            max_duration: 최대 처리 길이\n",
        "            skip_frames: 건너뛸 프레임 수\n",
        "\n",
        "        Returns:\n",
        "            성공시 True, 실패시 False\n",
        "        \"\"\"\n",
        "        if not self.model and not self.load_model():\n",
        "            return False\n",
        "\n",
        "        # 출력 디렉토리 생성\n",
        "        output_path = Path(output_filename)\n",
        "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # 다운로드 설정\n",
        "        ydl_opts = {\n",
        "            'format': 'mp4/best[height<=720]',  # 품질 제한 증가\n",
        "            'outtmpl': os.path.join(tempfile.gettempdir(), 'temp_video.%(ext)s'),\n",
        "            'quiet': True,\n",
        "        }\n",
        "\n",
        "        temp_video_path = None\n",
        "        cap = None\n",
        "        out = None\n",
        "\n",
        "        try:\n",
        "            # 영상 다운로드\n",
        "            with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "                logger.info(\"⬇️ YouTube 영상 다운로드 중...\")\n",
        "                info = ydl.extract_info(youtube_url, download=True)\n",
        "                temp_video_path = ydl.prepare_filename(info)\n",
        "                logger.info(f\"🎥 제목: {info['title']}\")\n",
        "                logger.info(f\"📊 길이: {info.get('duration', '알 수 없음')}초\")\n",
        "\n",
        "            # 비디오 캡처 초기화\n",
        "            cap = cv2.VideoCapture(temp_video_path)\n",
        "            if not cap.isOpened():\n",
        "                raise ValueError(\"영상 파일을 열 수 없습니다\")\n",
        "\n",
        "            # 영상 속성 가져오기\n",
        "            fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "            frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "            frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "            video_duration = total_frames / fps\n",
        "\n",
        "            # 시간 범위 설정\n",
        "            if end_time is None:\n",
        "                end_time = min(start_time + max_duration, video_duration)\n",
        "\n",
        "            start_time, end_time = self.validate_time_range(start_time, end_time, video_duration)\n",
        "\n",
        "            # 프레임 번호로 변환\n",
        "            start_frame = int(start_time * fps)\n",
        "            end_frame = int(end_time * fps)\n",
        "            process_duration = end_time - start_time\n",
        "\n",
        "            logger.info(f\"📹 영상 정보: {frame_width}x{frame_height}, {fps:.2f} FPS\")\n",
        "            logger.info(f\"🎯 처리 구간: {self.format_time(start_time)} ~ {self.format_time(end_time)} ({process_duration:.1f}초)\")\n",
        "\n",
        "            # 시작 프레임으로 이동\n",
        "            if start_frame > 0:\n",
        "                cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
        "\n",
        "            # 비디오 라이터 초기화\n",
        "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "            output_fps = fps / skip_frames\n",
        "            out = cv2.VideoWriter(output_filename, fourcc, output_fps, (frame_width, frame_height))\n",
        "\n",
        "            if not out.isOpened():\n",
        "                raise ValueError(\"출력 영상 파일을 생성할 수 없습니다\")\n",
        "\n",
        "            # 프레임 처리\n",
        "            frame_num = start_frame\n",
        "            processed_frames = 0\n",
        "            start_processing_time = time.time()\n",
        "\n",
        "            logger.info(\"🔄 YOLO 추론 시작...\")\n",
        "\n",
        "            while True:\n",
        "                ret, frame = cap.read()\n",
        "                if not ret or frame_num >= end_frame:\n",
        "                    break\n",
        "\n",
        "                # 성능을 위한 프레임 건너뛰기\n",
        "                if (frame_num - start_frame) % skip_frames == 0:\n",
        "                    try:\n",
        "                        # YOLO 추론 (기본 신뢰도 0.25 사용)\n",
        "                        results = self.model.predict(\n",
        "                            frame,\n",
        "                            imgsz=640,\n",
        "                            verbose=False,\n",
        "                            show=False,\n",
        "                            save=False\n",
        "                        )[0]\n",
        "\n",
        "                        # 결과 시각화\n",
        "                        annotated_frame = results.plot()\n",
        "                        out.write(annotated_frame)\n",
        "                        processed_frames += 1\n",
        "\n",
        "                        # 통계 업데이트\n",
        "                        if results.boxes is not None:\n",
        "                            detections = len(results.boxes)\n",
        "                            self.stats['total_detections'] += detections\n",
        "\n",
        "                            # 탐지된 클래스 추적\n",
        "                            for box in results.boxes:\n",
        "                                class_id = int(box.cls[0])\n",
        "                                class_name = self.model.names[class_id]\n",
        "                                self.stats['detected_classes'].add(class_name)\n",
        "\n",
        "                        # 진행률 표시\n",
        "                        if processed_frames % 30 == 0:\n",
        "                            progress = ((frame_num - start_frame) / (end_frame - start_frame)) * 100\n",
        "                            current_time = frame_num / fps\n",
        "                            elapsed_time = time.time() - start_processing_time\n",
        "\n",
        "                            logger.info(f\"⏳ 진행률: {progress:.1f}% | 시간: {self.format_time(current_time)} | \"\n",
        "                                      f\"처리 프레임: {processed_frames} | 경과: {elapsed_time:.1f}초\")\n",
        "\n",
        "                    except Exception as e:\n",
        "                        logger.warning(f\"⚠️ 프레임 {frame_num} 처리 중 오류: {e}\")\n",
        "                        continue\n",
        "\n",
        "                frame_num += 1\n",
        "\n",
        "            # 최종 통계\n",
        "            total_time = time.time() - start_processing_time\n",
        "            self.stats['processing_time'] = total_time\n",
        "            self.stats['total_frames_processed'] = processed_frames\n",
        "\n",
        "            logger.info(f\"✅ YOLO 영상 추론 완료!\")\n",
        "            logger.info(f\"📊 처리 시간: {total_time:.2f}초\")\n",
        "            logger.info(f\"📊 처리된 프레임: {processed_frames}\")\n",
        "            logger.info(f\"📊 총 탐지 수: {self.stats['total_detections']}\")\n",
        "            logger.info(f\"📊 탐지된 클래스: {', '.join(sorted(self.stats['detected_classes']))}\")\n",
        "            logger.info(f\"💾 출력 파일: {output_filename}\")\n",
        "\n",
        "            # 파일 크기 확인\n",
        "            if os.path.exists(output_filename):\n",
        "                file_size = os.path.getsize(output_filename) / (1024*1024)\n",
        "                logger.info(f\"📁 파일 크기: {file_size:.2f} MB\")\n",
        "\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"❌ 오류 발생: {e}\")\n",
        "            return False\n",
        "\n",
        "        finally:\n",
        "            # 리소스 정리\n",
        "            if cap:\n",
        "                cap.release()\n",
        "            if out:\n",
        "                out.release()\n",
        "            if temp_video_path and os.path.exists(temp_video_path):\n",
        "                try:\n",
        "                    os.remove(temp_video_path)\n",
        "                    logger.info(\"🗑️ 임시 파일 정리 완료\")\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "    def save_stats(self, filename: str = \"processing_stats.json\"):\n",
        "        \"\"\"처리 통계를 파일에 저장\"\"\"\n",
        "        stats_copy = self.stats.copy()\n",
        "        stats_copy['detected_classes'] = list(stats_copy['detected_classes'])\n",
        "        stats_copy['timestamp'] = datetime.now().isoformat()\n",
        "\n",
        "        with open(filename, 'w', encoding='utf-8') as f:\n",
        "            json.dump(stats_copy, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        logger.info(f\"📊 통계가 {filename}에 저장되었습니다\")\n",
        "\n",
        "\n",
        "def get_available_models() -> Dict[str, str]:\n",
        "    \"\"\"사용 가능한 YOLOv11 모델 목록\"\"\"\n",
        "    return {\n",
        "        'yolo11n.pt': 'YOLOv11 Nano - 가장 빠르고 가벼운 모델',\n",
        "        'yolo11s.pt': 'YOLOv11 Small - 속도와 정확도의 균형',\n",
        "        'yolo11m.pt': 'YOLOv11 Medium - 중간 크기 모델',\n",
        "        'yolo11l.pt': 'YOLOv11 Large - 높은 정확도',\n",
        "        'yolo11x.pt': 'YOLOv11 Extra Large - 최고 정확도'\n",
        "    }\n",
        "\n",
        "\n",
        "def interactive_setup() -> Tuple[str, str, float, Optional[float]]:\n",
        "    \"\"\"대화형 설정 인터페이스\"\"\"\n",
        "    print(\"\\n🎥 YouTube YOLO 영상 처리기\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # YouTube URL 입력\n",
        "    youtube_url = input(\"📋 YouTube 영상 URL을 입력하세요: \").strip()\n",
        "    if not youtube_url:\n",
        "        raise ValueError(\"URL이 필요합니다\")\n",
        "\n",
        "    # 모델 선택\n",
        "    models = get_available_models()\n",
        "    print(\"\\n🤖 사용 가능한 YOLOv11 모델:\")\n",
        "    for i, (model_name, description) in enumerate(models.items(), 1):\n",
        "        print(f\"{i}. {model_name} - {description}\")\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            choice = input(f\"\\n모델을 선택하세요 (1-{len(models)}, 기본값: 1): \").strip()\n",
        "            if not choice:\n",
        "                choice = \"1\"\n",
        "            choice = int(choice)\n",
        "            if 1 <= choice <= len(models):\n",
        "                model_path = list(models.keys())[choice-1]\n",
        "                break\n",
        "            else:\n",
        "                print(f\"❌ 1부터 {len(models)} 사이의 숫자를 입력하세요\")\n",
        "        except ValueError:\n",
        "            print(\"❌ 올바른 숫자를 입력하세요\")\n",
        "\n",
        "    # 영상 정보 가져오기\n",
        "    processor = YOLOVideoProcessor()\n",
        "    video_info = processor.get_video_info(youtube_url)\n",
        "\n",
        "    if not video_info:\n",
        "        raise ValueError(\"영상 정보를 가져올 수 없습니다\")\n",
        "\n",
        "    duration = video_info['duration']\n",
        "    print(f\"\\n📹 제목: {video_info['title']}\")\n",
        "    print(f\"⏱ 길이: {duration}초 ({processor.format_time(duration)})\")\n",
        "    print(f\"👤 업로더: {video_info['uploader']}\")\n",
        "\n",
        "    # 시간 범위 선택\n",
        "    print(f\"\\n⏰ 처리할 구간을 선택하세요 (0~{duration}초)\")\n",
        "    start_time = float(input(f\"🎬 시작 시간 (초 또는 분:초, 기본값: 0): \") or \"0\")\n",
        "\n",
        "    # 시간 형식 처리 (MM:SS)\n",
        "    if isinstance(start_time, str) and ':' in str(start_time):\n",
        "        parts = str(start_time).split(':')\n",
        "        if len(parts) == 2:\n",
        "            start_time = int(parts[0]) * 60 + int(parts[1])\n",
        "\n",
        "    end_input = input(f\"🏁 종료 시간 ({start_time+1}초~{duration}초, 기본값: 자동): \").strip()\n",
        "    end_time = None\n",
        "    if end_input:\n",
        "        if ':' in end_input:\n",
        "            parts = end_input.split(':')\n",
        "            if len(parts) == 2:\n",
        "                end_time = int(parts[0]) * 60 + int(parts[1])\n",
        "        else:\n",
        "            end_time = float(end_input)\n",
        "\n",
        "    return youtube_url, model_path, start_time, end_time\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"메인 함수 with 명령줄 인터페이스\"\"\"\n",
        "    # Jupyter 환경 체크 및 인수 정리\n",
        "    if JUPYTER_ENV or any('-f' in arg for arg in sys.argv):\n",
        "        # Jupyter 환경에서는 인수를 초기화\n",
        "        sys.argv = [sys.argv[0]]\n",
        "\n",
        "    parser = argparse.ArgumentParser(description='YouTube 영상 처리기 with YOLOv11')\n",
        "    parser.add_argument('--url', type=str, help='YouTube 영상 URL')\n",
        "    parser.add_argument('--model', type=str, default='yolo11n.pt', help='YOLO 모델 경로')\n",
        "    parser.add_argument('--start', type=float, default=0, help='시작 시간(초)')\n",
        "    parser.add_argument('--end', type=float, help='종료 시간(초)')\n",
        "    parser.add_argument('--duration', type=int, default=10, help='최대 처리 길이(초)')\n",
        "    parser.add_argument('--output', type=str, default='yolo_output.mp4', help='출력 파일명')\n",
        "    parser.add_argument('--skip-frames', type=int, default=5, help='건너뛸 프레임 수')\n",
        "    parser.add_argument('--interactive', action='store_true', help='대화형 모드 사용')\n",
        "\n",
        "    # Jupyter 환경에서도 알 수 없는 인수 허용\n",
        "    parser.add_argument('-f', '--connection-file', help='Jupyter kernel connection file (ignored)')\n",
        "\n",
        "    try:\n",
        "        args = parser.parse_args()\n",
        "    except SystemExit:\n",
        "        # argparse 오류 발생 시 대화형 모드로 전환\n",
        "        args = argparse.Namespace(\n",
        "            url=None, model='yolo11n.pt', start=0, end=None,\n",
        "            duration=10, output='yolo_output.mp4', skip_frames=5,\n",
        "            interactive=True\n",
        "        )\n",
        "\n",
        "    try:\n",
        "        if args.interactive or not args.url:\n",
        "            # 대화형 모드\n",
        "            youtube_url, model_path, start_time, end_time = interactive_setup()\n",
        "            output_filename = input(\"💾 출력 파일명 (기본값: yolo_output.mp4): \") or \"yolo_output.mp4\"\n",
        "            skip_frames = int(input(\"⏭ 건너뛸 프레임 수 (기본값: 5): \") or \"5\")\n",
        "        else:\n",
        "            # 명령줄 모드\n",
        "            youtube_url = args.url\n",
        "            model_path = args.model\n",
        "            start_time = args.start\n",
        "            end_time = args.end\n",
        "            output_filename = args.output\n",
        "            skip_frames = args.skip_frames\n",
        "\n",
        "        # 출력 파일 확장자 확인\n",
        "        if not output_filename.endswith('.mp4'):\n",
        "            output_filename += '.mp4'\n",
        "\n",
        "        # 영상 처리\n",
        "        processor = YOLOVideoProcessor(model_path)\n",
        "        success = processor.process_video(\n",
        "            youtube_url=youtube_url,\n",
        "            output_filename=output_filename,\n",
        "            start_time=start_time,\n",
        "            end_time=end_time,\n",
        "            max_duration=args.duration,\n",
        "            skip_frames=skip_frames\n",
        "        )\n",
        "\n",
        "        if success:\n",
        "            # 통계 저장\n",
        "            processor.save_stats()\n",
        "            print(\"\\n🎉 처리가 성공적으로 완료되었습니다!\")\n",
        "        else:\n",
        "            print(\"\\n❌ 처리 실패!\")\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n🚫 사용자에 의해 중단되었습니다\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"❌ 예상치 못한 오류: {e}\")\n",
        "\n",
        "\n",
        "# 빠른 실행을 위한 함수\n",
        "def quick_process(youtube_url: str, start_time: float = 0, duration: int = 10):\n",
        "    \"\"\"빠른 처리를 위한 간단한 함수\"\"\"\n",
        "    processor = YOLOVideoProcessor(\"yolo11n.pt\")  # 가장 빠른 모델 사용\n",
        "    return processor.process_video(\n",
        "        youtube_url=youtube_url,\n",
        "        start_time=start_time,\n",
        "        max_duration=duration,\n",
        "        skip_frames=3  # 더 빠른 처리를 위해 프레임 수 조정\n",
        "    )\n",
        "\n",
        "\n",
        "# Jupyter/Colab에서 직접 실행하기 위한 함수\n",
        "def run_in_jupyter():\n",
        "    \"\"\"Jupyter/Colab에서 직접 실행\"\"\"\n",
        "    try:\n",
        "        youtube_url, model_path, start_time, end_time = interactive_setup()\n",
        "        output_filename = input(\"💾 출력 파일명 (기본값: yolo_output.mp4): \") or \"yolo_output.mp4\"\n",
        "        skip_frames = int(input(\"⏭ 건너뛸 프레임 수 (기본값: 5): \") or \"5\")\n",
        "\n",
        "        if not output_filename.endswith('.mp4'):\n",
        "            output_filename += '.mp4'\n",
        "\n",
        "        processor = YOLOVideoProcessor(model_path)\n",
        "        success = processor.process_video(\n",
        "            youtube_url=youtube_url,\n",
        "            output_filename=output_filename,\n",
        "            start_time=start_time,\n",
        "            end_time=end_time,\n",
        "            max_duration=10,\n",
        "            skip_frames=skip_frames\n",
        "        )\n",
        "\n",
        "        if success:\n",
        "            processor.save_stats()\n",
        "            print(\"\\n🎉 처리가 성공적으로 완료되었습니다!\")\n",
        "        else:\n",
        "            print(\"\\n❌ 처리 실패!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"❌ 오류 발생: {e}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}