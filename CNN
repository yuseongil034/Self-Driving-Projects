# ğŸ§  CNN (Convolutional Neural Network) ì™„ë²½ ê°€ì´ë“œ

<div align="center">
  <img src="https://img.shields.io/badge/Python-3.7%2B-blue.svg" alt="Python">
  <img src="https://img.shields.io/badge/PyTorch-Latest-red.svg" alt="PyTorch">
  <img src="https://img.shields.io/badge/TensorFlow-2.x-orange.svg" alt="TensorFlow">
  <img src="https://img.shields.io/badge/Level-Beginner%20to%20Intermediate-green.svg" alt="Level">
</div>

ğŸ“ **ì—…ë°ì´íŠ¸**: 2024ë…„ ìµœì‹  ë²„ì „ìœ¼ë¡œ ì§€ì†ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ ì¤‘ì…ë‹ˆë‹¤.  
ğŸŒŸ ë„ì›€ì´ ë˜ì…¨ë‹¤ë©´ Starë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”!

---

## ğŸ“– ëª©ì°¨

1. [CNNì´ë€?](#1-cnnì´ë€)
2. [CNNì˜ ê¸°ë³¸ êµ¬ì„±ìš”ì†Œ](#2-cnnì˜-ê¸°ë³¸-êµ¬ì„±ìš”ì†Œ)
3. [ê° êµ¬ì„±ìš”ì†Œì˜ ì‘ë™ ì›ë¦¬](#3-ê°-êµ¬ì„±ìš”ì†Œì˜-ì‘ë™-ì›ë¦¬)
4. [ì£¼ìš” ìš©ì–´ ì •ë¦¬](#4-ì£¼ìš”-ìš©ì–´-ì •ë¦¬)
5. [CNNì˜ í•™ìŠµ ê³¼ì •](#5-cnnì˜-í•™ìŠµ-ê³¼ì •)
6. [ì½”ë“œ ì˜ˆì œ](#6-ì½”ë“œ-ì˜ˆì œ)
7. [ì‹¤ì „ íŒ](#7-ì‹¤ì „-íŒ)
8. [ì‹¤ì „ ì‘ìš©](#8-ì‹¤ì „-ì‘ìš©)
9. [ì°¸ê³ ìë£Œ](#9-ì°¸ê³ ìë£Œ)

---

## 1. CNNì´ë€?

**CNN (Convolutional Neural Network)**ì€ ì´ë¯¸ì§€ì™€ ê°™ì€ ê²©ì êµ¬ì¡°ì˜ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë° íŠ¹í™”ëœ ë”¥ëŸ¬ë‹ ëª¨ë¸ì…ë‹ˆë‹¤.

### ğŸ” ì£¼ìš” íŠ¹ì§•

- **ê³µê°„ì  êµ¬ì¡° ë³´ì¡´**: ì´ë¯¸ì§€ì˜ 2D êµ¬ì¡°ë¥¼ ìœ ì§€í•˜ë©´ì„œ í•™ìŠµ  
- **íŒŒë¼ë¯¸í„° ê³µìœ **: ê°™ì€ í•„í„°ë¥¼ ì´ë¯¸ì§€ ì „ì²´ì— ì ìš©í•˜ì—¬ íš¨ìœ¨ì„± ì¦ê°€  
- **í‰í–‰ ì´ë™ ë¶ˆë³€ì„±**: ê°ì²´ ìœ„ì¹˜ ë³€í™”ì—ë„ íŠ¹ì§• ê°ì§€ ê°€ëŠ¥  
- **ê³„ì¸µì  íŠ¹ì§• ì¶”ì¶œ**: ì €ìˆ˜ì¤€ â†’ ê³ ìˆ˜ì¤€ íŠ¹ì§•ì„ ë‹¨ê³„ì ìœ¼ë¡œ í•™ìŠµ  

### ğŸ†š ì¼ë°˜ ì‹ ê²½ë§ê³¼ ì°¨ì´ì 

| íŠ¹ì„±         | ì¼ë°˜ ì‹ ê²½ë§         | CNN                          |
|--------------|---------------------|-------------------------------|
| ì…ë ¥ í˜•íƒœ     | 1D ë²¡í„°             | 2D/3D í…ì„œ                    |
| ì—°ê²° ë°©ì‹     | ì™„ì „ ì—°ê²°            | ì§€ì—­ì  ì—°ê²°                   |
| íŒŒë¼ë¯¸í„° ìˆ˜   | ë§ìŒ                | ì ìŒ (ê³µìœ )                   |
| ê³µê°„ ì •ë³´     | ì†ì‹¤                | ë³´ì¡´                          |

---

## 2. CNNì˜ ê¸°ë³¸ êµ¬ì„±ìš”ì†Œ

ì…ë ¥ ì´ë¯¸ì§€ â†’ **í•©ì„±ê³±ì¸µ** â†’ **í™œì„±í™” í•¨ìˆ˜** â†’ **í’€ë§ì¸µ** â†’ ... â†’ **ì™„ì „ì—°ê²°ì¸µ** â†’ ì¶œë ¥

| êµ¬ì„± ìš”ì†Œ         | ì„¤ëª…                        |
|------------------|-----------------------------|
| í•©ì„±ê³±ì¸µ         | íŠ¹ì§• ì¶”ì¶œ                   |
| í™œì„±í™” í•¨ìˆ˜       | ë¹„ì„ í˜•ì„± ì¶”ê°€               |
| í’€ë§ì¸µ           | ì°¨ì› ì¶•ì†Œ, ìœ„ì¹˜ ë¶ˆë³€ì„±      |
| ì™„ì „ì—°ê²°ì¸µ       | ìµœì¢… ì¶œë ¥ ê³„ì‚°               |

---

## 3. ê° êµ¬ì„±ìš”ì†Œì˜ ì‘ë™ ì›ë¦¬

### 3.1 í•©ì„±ê³±ì¸µ

- í•„í„°(ì»¤ë„)ë¥¼ ì´ë¯¸ì§€ì— ìŠ¬ë¼ì´ë”©í•˜ë©° íŠ¹ì§•ë§µ ìƒì„±  
- ìˆ˜ì‹:  
  ```math
  (f * g)(x, y) = \sum_i \sum_j f(i,j) \cdot g(x - i, y - j)
  ```
- ì¶œë ¥ í¬ê¸° ê³„ì‚°:  
  ```
  ì¶œë ¥ = (ì…ë ¥ - í•„í„° + 2Ã—íŒ¨ë”©) / ìŠ¤íŠ¸ë¼ì´ë“œ + 1
  ```

### 3.2 í™œì„±í™” í•¨ìˆ˜

- ReLU: `f(x) = max(0, x)`  
- Leaky ReLU: `f(x) = max(0.01x, x)`

### 3.3 í’€ë§ì¸µ

- **Max Pooling**: ìœˆë„ìš° ë‚´ ìµœëŒ€ê°’ ì¶”ì¶œ  
- **Average Pooling**: í‰ê· ê°’ ì¶”ì¶œ

### 3.4 ì™„ì „ì—°ê²°ì¸µ

- ìˆ˜ì‹: `y = WÂ·x + b`

---

## 4. ì£¼ìš” ìš©ì–´ ì •ë¦¬

| ìš©ì–´         | ì„¤ëª…                             |
|--------------|----------------------------------|
| Filter        | íŠ¹ì§•ì„ ì¶”ì¶œí•˜ëŠ” ì‘ì€ í–‰ë ¬ (3Ã—3 ë“±) |
| Kernel        | í•„í„°ì™€ ë™ì¼ ì˜ë¯¸                  |
| Stride        | í•„í„° ì´ë™ ê°„ê²©                    |
| Padding       | ì…ë ¥ ì£¼ë³€ì— 0 ì¶”ê°€                 |
| Feature Map   | í•©ì„±ê³± ì—°ì‚° ê²°ê³¼                  |
| Receptive Field | ë‰´ëŸ°ì´ ì°¸ì¡°í•˜ëŠ” ì…ë ¥ ë²”ìœ„         |
| Depth         | ì±„ë„ ìˆ˜ (ì˜ˆ: RGB = 3)            |

**íŒ¨ë”© ì¢…ë¥˜**

- Valid: íŒ¨ë”© ì—†ìŒ
- Same: ì¶œë ¥ í¬ê¸° = ì…ë ¥ í¬ê¸°
- Full: í•„í„° í¬ê¸° - 1ë§Œí¼ íŒ¨ë”©

---

## 5. CNNì˜ í•™ìŠµ ê³¼ì •

### 5.1 ìˆœì „íŒŒ

1. ì…ë ¥ â†’ í•©ì„±ê³± â†’ í™œì„±í™” â†’ í’€ë§ ë°˜ë³µ
2. ì™„ì „ì—°ê²°ì¸µ â†’ ì˜ˆì¸¡ê°’ ë„ì¶œ

### 5.2 ì—­ì „íŒŒ

```math
1. L = CrossEntropy(y_pred, y_true)  
2. \frac{âˆ‚L}{âˆ‚W}, \frac{âˆ‚L}{âˆ‚b} ê³„ì‚°  
3. W â† W - Î±Â·âˆ‡W
```

### 5.3 ìµœì í™” ì•Œê³ ë¦¬ì¦˜

- **SGD**
- **Adam**
- **RMSprop**

---

## 6. ì½”ë“œ ì˜ˆì œ

### 6.1 PyTorch (MNIST)

<details>
<summary>ğŸ‘¨â€ğŸ’» ì½”ë“œ ë³´ê¸°</summary>

```python
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

class SimpleCNN(nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, 3, 1, 1)
        self.conv2 = nn.Conv2d(32, 64, 3, 1, 1)
        self.pool = nn.MaxPool2d(2, 2)
        self.fc1 = nn.Linear(64 * 7 * 7, 128)
        self.fc2 = nn.Linear(128, 10)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.pool(self.relu(self.conv1(x)))
        x = self.pool(self.relu(self.conv2(x)))
        x = x.view(-1, 64 * 7 * 7)
        x = self.relu(self.fc1(x))
        x = self.dropout(x)
        return self.fc2(x)

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.1307,), (0.3081,))
])

train_loader = DataLoader(
    datasets.MNIST('.', train=True, download=True, transform=transform),
    batch_size=64, shuffle=True
)

model = SimpleCNN()
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

def train(model, loader, criterion, optimizer, epochs=5):
    model.train()
    for epoch in range(epochs):
        for batch_idx, (data, target) in enumerate(loader):
            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, target)
            loss.backward()
            optimizer.step()
```

</details>

---

### 6.2 TensorFlow (CIFAR-10)

<details>
<summary>ğŸ‘¨â€ğŸ’» ì½”ë“œ ë³´ê¸°</summary>

```python
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.datasets import cifar10

(x_train, y_train), (x_test, y_test) = cifar10.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0
y_train = tf.keras.utils.to_categorical(y_train, 10)
y_test = tf.keras.utils.to_categorical(y_test, 10)

model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(10, activation='softmax')
])

model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])
model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))
```

</details>

---

## 7. ì‹¤ì „ íŒ

### 7.1 ê³¼ì í•© ë°©ì§€

- Dropout
- Batch Normalization
- Data Augmentation

### 7.2 í•˜ì´í¼íŒŒë¼ë¯¸í„°

| íŒŒë¼ë¯¸í„°       | ê¶Œì¥ê°’            | ì„¤ëª…                     |
|----------------|------------------|--------------------------|
| Learning Rate  | 0.001 ~ 0.01     | ì‘ìœ¼ë©´ ëŠë¦¼, í¬ë©´ ë°œì‚° ìœ„í—˜ |
| Batch Size     | 32 ~ 128         | GPU ë©”ëª¨ë¦¬ ê³ ë ¤           |
| Filter Size    | 3Ã—3, 5Ã—5         | ì‘ì€ í•„í„° ë°˜ë³µ ì¶”ì²œ       |
| Dropout Rate   | 0.2 ~ 0.5        | ê³¼ì í•© ë°©ì§€              |

### 7.3 í•™ìŠµ ìµœì í™”

- ReduceLROnPlateau
- EarlyStopping
- ModelCheckpoint

---

## 8. ì‹¤ì „ ì‘ìš©

- ì´ë¯¸ì§€ ë¶„ë¥˜ (Image Classification)  
- ê°ì²´ íƒì§€ (YOLO, SSD, Faster R-CNN)  
- ì´ë¯¸ì§€ ë¶„í•  (U-Net, FCN)  
- ì „ì´ í•™ìŠµ (Transfer Learning with ResNet ë“±)

---

## 9. ì°¸ê³ ìë£Œ

### ğŸ“š ì¶”ì²œ ë„ì„œ

- "Deep Learning" - Ian Goodfellow  
- "Hands-On Machine Learning" - AurÃ©lien GÃ©ron

### ğŸŒ ì˜¨ë¼ì¸ ê°•ì˜

- Stanford CS231n  
- Fast.ai Practical Deep Learning

### ğŸ”— ìœ ìš©í•œ ë§í¬

- [Papers with Code](https://paperswithcode.com)  
- [Distill.pub](https://distill.pub)  
- [Towards Data Science](https://towardsdatascience.com)
